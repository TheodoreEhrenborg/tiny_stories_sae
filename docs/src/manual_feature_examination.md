# Manual feature examination

Look at features 0, 1, 2

all the way to 10?

Proportion of dead features TODO

You can see the raw jsons here TODO

I'm going to drag you through 10 example
features. Why so many? 

(We can outsource this work to ChatGPT, but
for this project I think ChatGPT did a much 
worse job of ranking how specific the features)


The goal here is monosemanticity: 
We'd like each feature of the autoencoder to 
activate on input text with _one_ narrow theme, like
"cake/pie" or "numerical digits". 

I'm only looking at the top 10 examples (ranked by how
strongly the feature activates) for each feature.


(I'll look in more depth at feature 6 later)


### Feature 0
### Feature 1

### Feature 2

### Feature 3

### Feature 4

### Feature 5
### Feature 6
### Feature 7
### Feature 8
### Feature 9

## Comparing to raw LLM neurons

My prior is that the LLM activations
won't correspond to specific topics.

But we should give them the benefit of the doubt.

There are three ways we could interpret the activations:

Go through some examples in detail to show that ChatGPT is wrong

### Feature 0
### Feature 1

### Feature 2

### Feature 3

### Feature 4

### Feature 5
### Feature 6
### Feature 7
### Feature 8
### Feature 9
